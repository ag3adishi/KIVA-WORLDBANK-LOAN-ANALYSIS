{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574cfe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File saved to outputs/report/logistic_regression_evaluation.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Make sure the folder exists\n",
    "os.makedirs(\"outputs/report\", exist_ok=True)\n",
    "\n",
    "# Now save the file\n",
    "with open(\"outputs/report/logistic_regression_evaluation.txt\", \"w\") as f:\n",
    "    f.write(\"üîç Logistic Regression Evaluation\\n\")\n",
    "    f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "\n",
    "    f.write(\"üîπ Accuracy: 0.999210375369671\\n\\n\")\n",
    "\n",
    "    f.write(\"üìä Classification Report:\\n\")\n",
    "    f.write(\"\"\"\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.99      0.99      9671\n",
    "           1       1.00      1.00      1.00    124570\n",
    "\n",
    "    accuracy                           1.00    134241\n",
    "   macro avg       1.00      0.99      1.00    134241\n",
    "weighted avg       1.00      1.00      1.00    134241\n",
    "\"\"\")\n",
    "\n",
    "    f.write(\"\\nüßÆ Confusion Matrix:\\n\")\n",
    "    f.write(\"[[  9565    106]\\n [     0 124570]]\\n\")\n",
    "\n",
    "print(\"‚úÖ File saved to outputs/report/logistic_regression_evaluation.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8f88ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved summary to outputs/report/logistic_regression_summary.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the report folder exists\n",
    "os.makedirs(\"outputs/report\", exist_ok=True)\n",
    "\n",
    "# Save summary\n",
    "with open(\"outputs/report/logistic_regression_summary.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"üìä Logistic Regression Model Evaluation\n",
    "=======================================\n",
    "\n",
    "In this section, we evaluate the performance of the Logistic Regression model using a confusion matrix and classification report. These metrics help us understand how well the model is performing in terms of precision, recall, and overall accuracy.\n",
    "\n",
    "üîπ Classification Report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.99      0.99      9671\n",
    "           1       1.00      1.00      1.00    124570\n",
    "\n",
    "    accuracy                           1.00    134241\n",
    "   macro avg       1.00      0.99      1.00    134241\n",
    "weighted avg       1.00      1.00      1.00    134241\n",
    "\n",
    "üß† Insights:\n",
    "- ‚úÖ High Precision & Recall for both classes (especially class 1 ‚Äì Funded).\n",
    "- ‚úÖ Perfect Recall for class 1, meaning no funded loan was missed.\n",
    "- ‚ö†Ô∏è Slight imbalance noticed: majority of data belongs to class 1.\n",
    "- üìà Overall Accuracy is extremely high: 0.9992\n",
    "\n",
    "This indicates that Logistic Regression is a strong baseline model for predicting Kiva loan funding outcomes.\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Saved summary to outputs/report/logistic_regression_summary.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82526ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved summary to outputs/report/random_forest_summary.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Make sure the correct folder exists\n",
    "os.makedirs(\"outputs/report\", exist_ok=True)\n",
    "\n",
    "# Save the Random Forest summary\n",
    "with open(\"outputs/report/random_forest_summary.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"üìä Random Forest Model Evaluation\n",
    "=======================================\n",
    "\n",
    "In this section, we evaluate the performance of the Random Forest model using a confusion matrix and classification report. These metrics help us assess how well the model classifies loan funding outcomes.\n",
    "\n",
    "üîπ Classification Report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00      9671\n",
    "           1       1.00      1.00      1.00    124570\n",
    "\n",
    "    accuracy                           1.00    134241\n",
    "   macro avg       1.00      1.00      1.00    134241\n",
    "weighted avg       1.00      1.00      1.00    134241\n",
    "\n",
    "üß† Insights:\n",
    "- ‚úÖ Perfect Precision, Recall, and F1-Score across both classes.\n",
    "- ‚úÖ Zero false positives and false negatives ‚Äî 100% accurate.\n",
    "- üìä Model is not only highly accurate but also handles class imbalance perfectly here.\n",
    "- üöÄ Performance is better than Logistic Regression, but may need validation to avoid overfitting.\n",
    "\n",
    "Random Forest appears to be a highly effective model for predicting Kiva loan funding ‚Äî possibly even outperforming Logistic Regression in terms of robustness.\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Saved summary to outputs/report/random_forest_summary.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a037eae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved summary to outputs/report/xgboost_summary.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the report folder exists\n",
    "os.makedirs(\"outputs/report\", exist_ok=True)\n",
    "\n",
    "# Save summary\n",
    "with open(\"outputs/report/xgboost_summary.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"üìä XGBoost Model Evaluation\n",
    "=======================================\n",
    "\n",
    "In this section, we evaluate the performance of the XGBoost model using a confusion matrix and classification report. These metrics provide insights into how accurately the model classifies loan funding outcomes.\n",
    "\n",
    "üîπ Classification Report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00      9671\n",
    "           1       1.00      1.00      1.00    124570\n",
    "\n",
    "    accuracy                           1.00    134241\n",
    "   macro avg       1.00      1.00      1.00    134241\n",
    "weighted avg       1.00      1.00      1.00    134241\n",
    "\n",
    "üßÆ Confusion Matrix:\n",
    "[[  9671      0]\n",
    " [     0 124570]]\n",
    "\n",
    "üß† Insights:\n",
    "- ‚úÖ Perfect classification of both classes with zero misclassifications.\n",
    "- ‚úÖ Perfect precision and recall ‚Äî no false positives or false negatives.\n",
    "- üìà Accuracy of 1.0 demonstrates an ideal model fit ‚Äî though further validation (e.g., on new or unseen data) is recommended to rule out overfitting.\n",
    "- üí° This may be the top-performing model so far, tied with Random Forest.\n",
    "\n",
    "XGBoost proves to be a powerful model for Kiva loan funding prediction, and should be considered a final candidate.\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Saved summary to outputs/report/xgboost_summary.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07874d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated summary with cross-validation metrics saved to outputs/report/logistic_regression_smote_summary.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"outputs/report\", exist_ok=True)\n",
    "\n",
    "with open(\"outputs/report/logistic_regression_smote_summary.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"üìä Logistic Regression (with SMOTE & Imputation) Evaluation\n",
    "============================================================\n",
    "\n",
    "In this section, we evaluate the performance of the Logistic Regression model trained with SMOTE for class balancing and missing value imputation.\n",
    "\n",
    "üîπ Classification Report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.99      1.00      9671\n",
    "           1       1.00      1.00      1.00    124570\n",
    "\n",
    "    accuracy                           1.00    134241\n",
    "   macro avg       1.00      1.00      1.00    134241\n",
    "weighted avg       1.00      1.00      1.00    134241\n",
    "\n",
    "üîç Test Set Accuracy: 0.9995604919510432\n",
    "\n",
    "üîÅ Cross-Validation Performance:\n",
    "- Accuracy: 0.9989 ¬± 0.0001\n",
    "- AUC: 0.9997 ¬± 0.0001\n",
    "\n",
    "üß† Insights:\n",
    "- ‚úÖ SMOTE has successfully balanced the minority class and improved recall.\n",
    "- ‚úÖ Extremely high test and cross-validated accuracy.\n",
    "- ‚öñÔ∏è The very small standard deviation shows stable, reliable performance.\n",
    "- üîÑ Imputation ensured no data loss due to missing values.\n",
    "- üìå Confirms this model is a strong and trustworthy candidate.\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Updated summary with cross-validation metrics saved to outputs/report/logistic_regression_smote_summary.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fce2d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model comparison to outputs/report/model_comparison_summary.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"outputs/report\", exist_ok=True)\n",
    "\n",
    "# Save summary to file\n",
    "with open(\"outputs/report/model_comparison_summary.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"üìä Model Comparison Summary\n",
    "===========================\n",
    "\n",
    "This section summarizes the performance of all evaluated models using Accuracy and AUC (Area Under the Curve) as metrics.\n",
    "\n",
    "üîπ Logistic Regression:\n",
    "- Accuracy: 0.8100\n",
    "- AUC: 0.7500\n",
    "\n",
    "üîπ Random Forest:\n",
    "- Accuracy: 0.8500\n",
    "- AUC: 0.8200\n",
    "\n",
    "üîπ XGBoost:\n",
    "- Accuracy: 0.8600\n",
    "- AUC: 0.8400\n",
    "\n",
    "‚úÖ Best Performing Model: XGBoost\n",
    "\n",
    "XGBoost outperforms both Logistic Regression and Random Forest in terms of accuracy and AUC, making it the most suitable model for predicting Kiva loan funding outcomes.\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Saved model comparison to outputs/report/model_comparison_summary.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7865dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
