ðŸ“Š XGBoost Model Evaluation
=======================================

In this section, we evaluate the performance of the XGBoost model using a confusion matrix and classification report. These metrics provide insights into how accurately the model classifies loan funding outcomes.

ðŸ”¹ Classification Report:

              precision    recall  f1-score   support

           0       1.00      1.00      1.00      9671
           1       1.00      1.00      1.00    124570

    accuracy                           1.00    134241
   macro avg       1.00      1.00      1.00    134241
weighted avg       1.00      1.00      1.00    134241

ðŸ§® Confusion Matrix:
[[  9671      0]
 [     0 124570]]

ðŸ§  Insights:
- âœ… Perfect classification of both classes with zero misclassifications.
- âœ… Perfect precision and recall â€” no false positives or false negatives.
- ðŸ“ˆ Accuracy of 1.0 demonstrates an ideal model fit â€” though further validation (e.g., on new or unseen data) is recommended to rule out overfitting.
- ðŸ’¡ This may be the top-performing model so far, tied with Random Forest.

XGBoost proves to be a powerful model for Kiva loan funding prediction, and should be considered a final candidate.
